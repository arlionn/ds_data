{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1670224b",
   "metadata": {},
   "source": [
    "# 水果和蔬菜价格数据处理\n",
    "\n",
    "## 下载压缩文件\n",
    "\n",
    "\n",
    "### ChatGPT  \n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "目的：自动从网页端下载 .zip 数据文件\n",
    "\n",
    "1. 网址：https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\n",
    "2. 网页源文件：view-source:https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\n",
    "3. 需要下载的文件：vegetables-####.zip, fruit-###.zip\n",
    "   - 规则：包含 `vegetables` 或 `fruit` 关键词，且后缀为 `.zip` 的所有文件\n",
    "   - note: 我通过右击下载链接的方式，发现 **fruit-2013.zip** 对应的下载网址是：`https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/51035/fruit-2013.zip?v=41740`\n",
    "4. 目标文件夹： 'D:\\Github\\ds_data\\data\\Fruit_and_Vegetable_Prices\\data_raw'\n",
    "5. 语言：Python \n",
    "   \n",
    ":::\n",
    "\n",
    "- 文件清单：\n",
    "  - `vegetables-2013.zip`, `vegetables-2016.zip`, `vegetables-2020.zip`, \n",
    "  - `fruit-2013.zip`, `fruit-2016.zip`, `fruit-2020.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bc3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 6 个 .zip 文件链接。\n",
      "正在下载：fruit-2013.zip ...\n",
      "下载完成：fruit-2013.zip\n",
      "正在下载：fruit-2016.zip ...\n",
      "下载完成：fruit-2016.zip\n",
      "正在下载：fruit-2020.zip ...\n",
      "下载完成：fruit-2020.zip\n",
      "正在下载：vegetables-2013.zip ...\n",
      "下载完成：vegetables-2013.zip\n",
      "正在下载：vegetables-2016.zip ...\n",
      "下载完成：vegetables-2016.zip\n",
      "正在下载：vegetables-2020.zip ...\n",
      "下载完成：vegetables-2020.zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# 设置 URL 和目标路径\n",
    "base_url = \"https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\"\n",
    "target_folder = r\"D:\\Github\\ds_data\\data\\Fruit_and_Vegetable_Prices\\data_raw\"\n",
    "\n",
    "# 创建目标路径\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# 获取网页 HTML\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "response = requests.get(base_url, headers=headers)\n",
    "html_text = response.text\n",
    "\n",
    "# 用正则表达式匹配 .zip 链接（fruit 或 vegetables）\n",
    "pattern = r'href=\"(.*?(fruit|vegetables)[^\"]*?\\.zip[^\"]*?)\"'\n",
    "matches = re.findall(pattern, html_text, flags=re.IGNORECASE)\n",
    "\n",
    "# 构造完整链接\n",
    "zip_links = [urljoin(base_url, m[0]) for m in matches]\n",
    "\n",
    "print(f\"共找到 {len(zip_links)} 个 .zip 文件链接。\")\n",
    "\n",
    "# 下载文件\n",
    "for link in zip_links:\n",
    "    filename = os.path.basename(link.split(\"?\")[0])  # 去掉 ?v=xxx 参数\n",
    "    save_path = os.path.join(target_folder, filename)\n",
    "    print(f\"正在下载：{filename} ...\")\n",
    "\n",
    "    try:\n",
    "        with requests.get(link, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"下载完成：{filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"下载失败：{filename}，原因：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b0e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\ds_data\\data\\Fruit_and_Vegetable_Prices\\data_raw\n",
      "['copy', 'downloader.log', 'fruit-2013.zip', 'fruit-2016.zip', 'fruit-2020.zip', 'vegetables-2013.zip', 'vegetables-2016.zip', 'vegetables-2020.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(target_folder)\n",
    "print(os.getcwd())\n",
    "print(os.listdir(target_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15445382",
   "metadata": {},
   "source": [
    "### 豆包\n",
    "\n",
    "> [豆包问答过程](https://www.doubao.com/thread/w24fdaaf190d3f71a)\n",
    "\n",
    "- 我用豆包只是为了测试我的提示词是否合理，现已达到目标，因此，下面的代码无需重复执行了。\n",
    "\n",
    "**Round 1** 提示词发送后，豆包给的代码可以运行，但无法下载文件。不过豆包自动生成了一个日志文件，内容如下：\n",
    "\n",
    "```txt\n",
    "2025-05-20 00:54:22,003 - INFO - 开始爬取下载链接...\n",
    "2025-05-20 00:54:24,145 - WARNING - 未找到符合条件的下载链接\n",
    "```\n",
    "\n",
    "我把上述内容作为 **Round 2** 的提示词反馈给豆包，它这次返回的代码可以正常下载数据了。 \n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "(Round 1)：\n",
    "\n",
    "目的：自动从网页端下载 .zip 数据文件\n",
    "\n",
    "1. 网址：https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\n",
    "2. 网页源文件：view-source:https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\n",
    "3. 需要下载的文件：vegetables-####.zip, fruit-###.zip\n",
    "   - 规则：包含 `vegetables` 或 `fruit` 关键词，且后缀为 `.zip` 的所有文件\n",
    "   - note: 我通过右击下载链接的方式，发现 **fruit-2013.zip** 对应的下载网址是：`https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/51035/fruit-2013.zip?v=41740`\n",
    "4. 目标文件夹： 'D:\\Github\\ds_data\\data\\Fruit_and_Vegetable_Prices\\data_raw'\n",
    "5. 语言：Python \n",
    "\n",
    "(Round 2)：\n",
    "\n",
    "2025-05-20 00:54:22,003 - INFO - 开始爬取下载链接...    \n",
    "2025-05-20 00:54:24,145 - WARNING - 未找到符合条件的下载链接\n",
    ":::\n",
    "\n",
    "以下是豆包返回的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b85bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 豆包\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='downloader.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_links(url):\n",
    "    \"\"\"提取网页中符合规则的.zip文件链接（包括文本中的隐藏链接）\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"无法访问网页: {e}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    base_url = urljoin(url, '/')  # 基础URL\n",
    "    links = []\n",
    "    \n",
    "    # 匹配文本中的链接模式（如 Archived 2013 Data Tables for Fruit）\n",
    "    pattern = r'Archived\\s+(\\d{4})\\s+Data Tables for\\s+(Fruit|Vegetables)'\n",
    "    matches = re.findall(pattern, soup.get_text(), re.IGNORECASE)\n",
    "    \n",
    "    for year, category in matches:\n",
    "        # 构造.zip文件的URL（根据已知格式推断）\n",
    "        # 示例：https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/51035/fruit-2013.zip\n",
    "        file_type = category.lower()\n",
    "        url_suffix = f\"{file_type}-{year}.zip\"\n",
    "        # 注意：此处URL路径可能需要根据实际情况调整，当前为示例路径\n",
    "        zip_url = f\"https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/51035/{url_suffix}\"\n",
    "        \n",
    "        # 验证链接格式（包含fruit/vegetables和.zip）\n",
    "        if (file_type in ['fruit', 'vegetables'] and \n",
    "            zip_url.lower().endswith('.zip')):\n",
    "            links.append(zip_url)\n",
    "    \n",
    "    return links\n",
    "\n",
    "def download_file(url, target_folder):\n",
    "    # 保持原有逻辑不变（见上文）\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    filename = os.path.basename(urlparse(url).path)\n",
    "    local_path = os.path.join(target_folder, filename)\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        logger.info(f\"文件已存在: {filename}\")\n",
    "        return local_path\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"开始下载: {filename}\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        logger.info(f\"下载完成: {filename}\")\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"下载失败: {filename}, 错误: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\"\n",
    "    target_folder = r\"D:\\Github\\ds_data\\data\\Fruit_and_Vegetable_Prices\\data_raw\"\n",
    "    \n",
    "    logger.info(\"开始爬取下载链接...\")\n",
    "    links = get_links(url)\n",
    "    \n",
    "    if not links:\n",
    "        logger.warning(\"未找到符合条件的下载链接\")\n",
    "    else:\n",
    "        logger.info(f\"找到 {len(links)} 个符合条件的下载链接: {links}\")\n",
    "        for link in links:\n",
    "            download_file(link, target_folder)\n",
    "    \n",
    "    logger.info(\"下载任务完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943bde4",
   "metadata": {},
   "source": [
    "## 解压缩包-合并单个 csv 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0aff5d",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 把以 `fruit` 开头的 .zip 文件解压到 [fruit] 文件夹中\n",
    "- 把以 `vegetables` 开头的 zip 文件解压到 [vegetables] 文件夹中\n",
    "- 完成后，统计上述两个新生成的子文件夹内的文件数量\n",
    "  \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4640ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit 文件夹内文件数量: 117\n",
      "vegetables 文件夹内文件数量: 177\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# 创建目标子文件夹\n",
    "fruit_folder = os.path.join(target_folder, \"fruit\")\n",
    "vegetables_folder = os.path.join(target_folder, \"vegetables\")\n",
    "os.makedirs(fruit_folder, exist_ok=True)\n",
    "os.makedirs(vegetables_folder, exist_ok=True)\n",
    "\n",
    "# 遍历 target_folder 下的所有 zip 文件并解压\n",
    "for filename in os.listdir(target_folder):\n",
    "    if filename.lower().endswith(\".zip\"):\n",
    "        zip_path = os.path.join(target_folder, filename)\n",
    "        if filename.startswith(\"fruit\"):\n",
    "            extract_path = fruit_folder\n",
    "        elif filename.startswith(\"vegetables\"):\n",
    "            extract_path = vegetables_folder\n",
    "        else:\n",
    "            continue\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "# 统计文件数量\n",
    "fruit_files = [f for f in os.listdir(fruit_folder) if os.path.isfile(os.path.join(fruit_folder, f))]\n",
    "vegetables_files = [f for f in os.listdir(vegetables_folder) if os.path.isfile(os.path.join(vegetables_folder, f))]\n",
    "\n",
    "print(f\"fruit 文件夹内文件数量: {len(fruit_files)}\")\n",
    "print(f\"vegetables 文件夹内文件数量: {len(vegetables_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2900f0",
   "metadata": {},
   "source": [
    "### 合并与结构化\n",
    "\n",
    "#### 观察各个年度的文件命名规则的差别\n",
    "\n",
    "[fruit] 文件夹下的前 8 个文件列举如下：\n",
    "  \n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520012922.png)\n",
    "\n",
    "仔细对比后发现：\n",
    "\n",
    "- 2016 年数据的有两个文件：一个是 .csv 格式的，另一个是 .xlsx 格式的。对比文档内容后发现，两份数据文件的内容完全相同。进一步抽查了其十种水果在 2016 年的数据，发现都存在上述规律。\n",
    "  - 最终决定：删除 [fruit] 文件夹下的 .csv 文件，保留 .xlsx 文件，以便后续采用循环语句进行统一处理。 \n",
    "- 为了保持各年度上的文件命名方式统一，做如下处理：\n",
    "  - 将 [fruit] 文件夹下的所有文件名中的 ` ` (空格) 替换为 `_` (下划线)；\n",
    "  - 将文件名中的有英文单词替换为小写字母。\n",
    "\n",
    "#### 结构化处理\n",
    "\n",
    "- 分析 csv 文件的内部结构：非结构化 >> 结构化\n",
    "   \n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520013804.png)\n",
    "\n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520013503.png) \n",
    "\n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520013356.png)\n",
    "\n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520092820.png)\n",
    "\n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520091552.png)\n",
    "\n",
    "   ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520092543.png)\n",
    "\n",
    "Apricots 的数据结构如下：\n",
    "\n",
    "![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520084449.png)\n",
    "\n",
    "我们需要把上述半结构化的数据转换成整洁数据。浏览网页，发现 [ALL FRUITS – Average prices (CSV format)](https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/51035/Fruit-Prices-2022.csv?v=74889) 页面已经有了整洁数据的格式。该数据文件的格式为：\n",
    "\n",
    " ![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250520083653.png)\n",
    "\n",
    "- 观察到 csv 文件的第一行是表头，第二行是数据类型，第三行是数据内容\n",
    "- 因此，读取 csv 文件时，指定 `header=2`，并且 `skiprows=3`，这样就可以直接读取数据了\n",
    "- 读取数据时，指定 `usecols` 参数，选择需要的列"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
